---
title: "simulations"
author: "Charles T. Gray"
draft: true
#date: "14 August 2018; updated `r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

```{r message=FALSE}
# packages
library(tidyverse)
library(tictoc) # for timing

```

```{r reproducibile}
# set seed for reproducibility
set.seed(38) # 'tis a fine age to be

```

## single-study simulation

The original snippet. 

```{r eval=FALSE}
# find the original snippet
lnormPAR <- function(m, iqr){
  mu <- log(m) 
  sigma <- (mu + log(1/2*(iqr + sqrt(iqr^2 + 4*exp(2*mu)))/exp(2*mu)))/qnorm(0.75)
  list(mu = mu, sigma = sigma)
}

medianInt <- function(m, iqr, n){
  par <- lnormPAR(m, iqr)
  V <- 1/4/dlnorm(m, par$mu, par$sigma)^2/n
  
  ci <- m + c(-1, 1)*qnorm(0.975)*sqrt(V)
  
  ci  
} 

x <- rlnorm(100)
m <- median(x)
iqr <- IQR(x)


medianInt(m, iqr, n)

trials <- 1000
cis <- matrix(0, trials, 2)

true.m <- 1
n <- 100

for(i in 1:trials){
  print(i)
  x <- rlnorm(n)
  m <- median(x)
  iqr <- IQR(x)
  
  cis[i, ] <- medianInt(m, iqr, n)
}

mean(cis[ , 1] < true.m & cis[ , 2] > true.m)
```


## single simulation

### simulation parameters

- sample size
- distribution + parameters

### simulation output

- estimators
- confidence intervals
- bias
- list or table? not sure best output

```{r start timer}
tic("total") # set timer for all
```

### recreate luke's algorithm



```{r simulations}
# create a table of density functions

# check it does what I think it does with character strings
(
  list(
    prefix = c("d", "p", "q", "r"),
    dist = c("lnorm", "exp")
  ) %>%
    cross_df() %>%
    mutate(fn = map2_chr(
      prefix,
      dist,
      .f = function(prefix, dist)
        glue::glue('{prefix}', '{dist}')
    )) %>%
    spread(key = prefix,
           value = fn)
)

# then convert to functions.
(
  dist_fns <- list(
    prefix = c("d", "p", "q", "r"),
    dist = c("lnorm", "exp")
  ) %>%
    cross_df() %>%
    mutate(fn = map2(
      prefix,
      dist,
      .f = function(prefix, dist)
        glue::glue('{prefix}', '{dist}') %>% get()
    )) %>%
    spread(key = prefix,
           value = fn)
)



# check we get functions back
dist_fns[[sample(c(1, 2), 1), sample(seq(2, 5), 1)]] %>% class()

# check the functions are what I think they are
dist_fns[[1, 2]](1) == dexp(1)

```


```{r}
# simulation meta-parameters
# using = for things that will be arguments eventually
distn = "lnorm"
par = c(0, 1)
n = 100
density_fns <- dist_fns %>% filter(dist == distn)

# meta-meta-parameter! l
trials = 1000

# simulate data
observations <- density_fns[["r"]][[1]](10, meanlog = par[1], sdlog = par[2])
# placeholder until I figure out this density function thing

# sample data according to simulation parameters

# calculate summary statistics

# calculate estimators

# return estimators

# return confidence intervals?

# wideform return rather than longform - then gather?

# how to output as as df ultimately?

```




```{r end timer}
toc() # end timer for all

```




### simulating over several different distributions

```{r eval=FALSE}
# enlightening code snippet from Mitch. 
distfns <- function(dist, prefix = c("d", "p", "q", "r")){
 map(paste0(prefix, dist),
   ~ get(.x, mode = "function")
 )
}
```

How cool is that? 

Now that I have a table of functions, I can join it later on as required. 


### simulation with incomprehensible eval text thing

So I keep hearing about tidy evaluation, and I have a feeling that when I get my heada round, it'll open things up like how tidy did. I thought perhaps I didn't need it, but now I'm back to thinking I do to solve this problem. (Should ask Mike Penguin again.) In the meantime, let's see if I can get a functional simulation, even if I have to eval parse hack text my way through the distribution component.

I have to write up a new raw data simulation, mostly because I can't quite remember the maths of the random sampling for meta-analyses, so I might as well learn how to do it in a purrier way.  

Using this blog post for [inspiration](https://aosmith.rbind.io/2018/06/05/a-closer-look-at-replicate-and-purrr/)^[1], I want to see if I can find a nicer way to writer simulations. (I recently learnt at useR! that I can be described as an incorrigible refactorer.) 

[^1]: Much obliged, [Ariel](https://twitter.com/hashtag/aosmith)!

## meta-parameters

I want to (re)run trials of simulations for:

- different sample sizes
- different distributions
- (also different arm adjustment in the meta-analysis simulation)

## meta-analysis simulation

> write an intro

The goal of this post is to understand what past Charles[^1] did to simulate meta-analysis data, and ask why it seemed convincing that it was the best way. Ideally, I'd like to convince myself using simulations that it *is* the best way, and compare it to what other people are doing. 

[^1]: Life threw a few curve balls that meant I took a break from research over the last year. I'm trying to piece together the bits and pieces of code and mathematics that made sense at some point. 

### What did past Charles do?

#### from code to mathematics

Assume the log-ratio of medians $\mathrm{LR_k}$ for the $k^\mathrm{th}$ study can be thought of in terms of the overall average log-ratio of medians $\mathrm{LR}$, the variation from that average of this study $\gamma_k$, along with some sampling error $\varepsilon_k$, 
$$\mathrm{LR_k} = \mathrm{LR} + \gamma_k + \varepsilon_k.$$  

index | description
:---------------------------|------:
$i \in 1, \dots, n$ | observation
$j \in \{1,2\}$ | arm
$k \in 1, \dots, K$ | study

-|lognormal|exponential|pareto
----|---------------------------|---------------------------------|----------------------------------
$\gamma_k$| $~\mathrm N(0, \tau^2)$ | $~\mathrm{logN}(0, \tau)$ | $~\mathrm{logN}(0, \tau)$ | 
$x_{ijk}$  | $~\mathrm{logN}(\mu_j + \gamma_k/2, \sigma_j)$ |$~\mathrm{exp}(\lambda = \lambda_j \cdot \gamma_k / 2)$ | $~\mathrm{pareto}(\text{scale} = \lambda_j \cdot \gamma_k/2, \text{shape} = \alpha_j)$

I fixed the parameters $\mu$, $\sigma$, $\alpha_j$, $\lambda_j$.

#### from mathematics to code


## What is best practice?

> todo 